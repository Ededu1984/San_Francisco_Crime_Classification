{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing python libraries"
      ],
      "metadata": {
        "id": "7n6exrwQAOYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWv1AcSqeH5R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "from statistics import mean\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaWjSC9oeo-w",
        "outputId": "be923fdb-7af7-4972-eadd-2603d03b5d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCSPPOKo-OR3"
      },
      "source": [
        "### Classification models - Base models\n",
        "\n",
        "Some base models are created to use in the stacking model\n",
        "Random Forest, LightGBM, Logistic Regression, XGBoost, GNB and extra decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAjAIzw3eIXy"
      },
      "outputs": [],
      "source": [
        "def run_training(fold: int, model: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(\"drive/MyDrive/train_folds.csv\")\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    xtrain = df_train.drop('Category', axis=1)\n",
        "    xvalid = df_valid.drop('Category', axis=1)\n",
        "    ytrain = df_train['Category']\n",
        "    yvalid = df_valid['Category']\n",
        "    \n",
        "    scaler = MaxAbsScaler()\n",
        "    selection = SelectPercentile(chi2, percentile=50)\n",
        "    xvalid = scaler.fit_transform(xvalid)\n",
        "\n",
        "    if model == 'Random_Forest':\n",
        "      clf = RandomForestClassifier(max_depth=8, n_estimators=100)\n",
        "      column_name = 'rf_pred'\n",
        "      \n",
        "    elif model == 'LightGBM':\n",
        "      clf = LGBMClassifier()\n",
        "      column_name = 'lgbm_pred'\n",
        "\n",
        "    elif model == 'Logistic_Regression':\n",
        "      clf = LogisticRegression()\n",
        "      column_name = 'lr_pred'\n",
        "\n",
        "    elif model == 'XGBoost':\n",
        "      clf = XGBClassifier(verbosity=0)\n",
        "      column_name = 'xgb_pred'\n",
        "\n",
        "    elif model == 'GNB':\n",
        "      clf = GaussianNB()\n",
        "      column_name = 'gnb_pred'\n",
        "      \n",
        "    else:\n",
        "      clf = ExtraTreesClassifier()\n",
        "      column_name = 'ext_pred'\n",
        "\n",
        "\n",
        "    clf_pipe = make_pipeline(scaler, selection, clf)\n",
        "    clf_pipe.fit(xtrain, ytrain)  \n",
        "    pred_train = clf_pipe.predict_proba(xtrain)\n",
        "    pred_test = clf_pipe.predict_proba(xvalid)\n",
        "\n",
        "    train_loss = log_loss(ytrain, pred_train)\n",
        "    test_loss = log_loss(yvalid, pred_test)\n",
        "    print(f\"fold={fold}, train_loss={train_loss} - test_loss={test_loss}\")\n",
        "\n",
        "    prob_list = []\n",
        "    for i in pred_test:\n",
        "        max_prob = i.max()\n",
        "        probs = list(i)\n",
        "        prob = probs.index(max_prob)\n",
        "        prob_list.append(prob)\n",
        "\n",
        "    df_valid[column_name] = prob_list\n",
        "\n",
        "    return df_valid[['id', 'Category','kfold', column_name]], train_loss, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uul9i_AQeIaa",
        "outputId": "db7728c7-c00e-4085-ef56-b5bdffd27e2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Base model 1 - Random_Forest\n",
            "fold=0, train_loss=2.541369617026053 - test_loss=2.6219590180071726\n",
            "fold=1, train_loss=2.543113449807293 - test_loss=2.6194181468083717\n",
            "fold=2, train_loss=2.542666503651043 - test_loss=2.619097629244715\n",
            "fold=3, train_loss=2.543054858750583 - test_loss=2.620417616286956\n",
            "fold=4, train_loss=2.5429817045922265 - test_loss=2.6204241908129515\n",
            "(878049, 4)\n",
            "--------------------------------------------------------------------------------\n",
            "Base model 2 - XGBoost\n",
            "fold=0, train_loss=2.530676807569018 - test_loss=2.6716134783232053\n",
            "fold=1, train_loss=2.531775544554962 - test_loss=2.670121415041145\n",
            "fold=2, train_loss=2.53154569981889 - test_loss=2.6681256893175176\n",
            "fold=3, train_loss=2.5313877291716236 - test_loss=2.670184492660298\n",
            "fold=4, train_loss=2.5313150242660876 - test_loss=2.668180791586567\n",
            "(878049, 4)\n",
            "--------------------------------------------------------------------------------\n",
            "Base model 3 - Logistic_Regression\n",
            "fold=0, train_loss=2.57124996866328 - test_loss=2.6414511742083966\n",
            "fold=1, train_loss=2.571908563252529 - test_loss=2.6379614166186975\n",
            "fold=2, train_loss=2.5718845722946533 - test_loss=2.6388601334574964\n",
            "fold=3, train_loss=2.571944605567557 - test_loss=2.638968453056544\n",
            "fold=4, train_loss=2.571564332623518 - test_loss=2.639048288386421\n",
            "(878049, 4)\n",
            "--------------------------------------------------------------------------------\n",
            "Base model 4 - Extra_Trees_Classifier\n",
            "fold=0, train_loss=2.293601450787743 - test_loss=3.4500243077380777\n",
            "fold=1, train_loss=2.295516929271153 - test_loss=3.4429986931332746\n",
            "fold=2, train_loss=2.2956048233072277 - test_loss=3.435795962560938\n",
            "fold=3, train_loss=2.2951895251879 - test_loss=3.4487087179970652\n",
            "fold=4, train_loss=2.295792463954623 - test_loss=3.471255961390992\n",
            "(878049, 4)\n",
            "--------------------------------------------------------------------------------\n",
            "Base model 5 - GNB\n",
            "fold=0, train_loss=33.19770256219427 - test_loss=33.32189254014428\n",
            "fold=1, train_loss=31.20710362962777 - test_loss=31.318684682698407\n",
            "fold=2, train_loss=32.308273468732054 - test_loss=32.38747397311226\n",
            "fold=3, train_loss=32.68828784141191 - test_loss=32.723336518210225\n",
            "fold=4, train_loss=32.01804950855092 - test_loss=32.13472505343413\n",
            "(878049, 4)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "base_models = ['Random_Forest', 'XGBoost', 'Logistic_Regression', 'Extra_Trees_Classifier', 'GNB']\n",
        "\n",
        "for n, i in enumerate(base_models):\n",
        "  print(\"-\"*80)\n",
        "  print(f\"Base model {n+1} - \" + i)\n",
        "  model = i\n",
        "  dfs = []\n",
        "  train_loss = []\n",
        "  test_loss = []\n",
        "\n",
        "  for j in range(5):\n",
        "      temp_df, train_, test_ = run_training(j, model)\n",
        "      dfs.append(temp_df)\n",
        "      train_loss.append(train_)\n",
        "      test_loss.append(test_)\n",
        "\n",
        "  fin_valid_df = pd.concat(dfs)\n",
        "  print(fin_valid_df.shape)\n",
        "  fin_valid_df.to_csv(\"drive/MyDrive/model_preds/\" + i + \".csv\", index=False)\n",
        "print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTC-1vHTNGlx"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x-zeXAl-Koy"
      },
      "source": [
        "### Neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8v70G8xNP88"
      },
      "outputs": [],
      "source": [
        "def run_neural_network(fold: int) -> pd.DataFrame:\n",
        "    df = pd.read_csv(\"drive/MyDrive/train_folds.csv\")\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    xtrain = df_train.drop('Category', axis=1)\n",
        "    xvalid = df_valid.drop('Category', axis=1)\n",
        "    ytrain = df_train['Category']\n",
        "    yvalid = df_valid['Category']\n",
        "\n",
        "\n",
        "    scaler = MaxAbsScaler()\n",
        "    xvalid = scaler.fit_transform(xvalid)\n",
        "    xtrain = scaler.fit_transform(xtrain)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_shape=(xtrain.shape[1],)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(100))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(80))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(60))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(39))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(optimizer ='adam',\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "    model.fit(xtrain, ytrain, \n",
        "            batch_size = 32, \n",
        "            epochs = 20, \n",
        "            verbose = 0, \n",
        "            validation_data=(xvalid,yvalid))\n",
        "\n",
        "    pred_train = model.predict(xtrain)\n",
        "    pred_test = model.predict(xvalid)\n",
        "    train_loss = log_loss(ytrain, pred_train)\n",
        "    test_loss = log_loss(yvalid, pred_test)\n",
        "    print(f\"fold={fold}, train_loss={train_loss} - test_loss={test_loss}\")\n",
        "\n",
        "    prob_list = []\n",
        "    for i in pred_test:\n",
        "        max_prob = i.max()\n",
        "        probs = list(i)\n",
        "        prob = probs.index(max_prob)\n",
        "        prob_list.append(prob)\n",
        "\n",
        "    df_valid['nn_pred'] = prob_list\n",
        "\n",
        "    return df_valid[['id', 'Category','kfold', 'nn_pred']], train_loss, test_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "591XmBuqNHjb",
        "outputId": "f28317a6-c447-40e4-c9ca-bc6fe71bd9f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Neural Network\n",
            "fold=0, train_loss=2.520209292880304 - test_loss=2.5351018119789015\n",
            "fold=1, train_loss=2.520707105994488 - test_loss=2.529958650641439\n",
            "fold=2, train_loss=2.519396584924139 - test_loss=2.5306858517655098\n",
            "fold=3, train_loss=2.522297162887339 - test_loss=2.534251552782488\n",
            "fold=4, train_loss=2.5212766518861836 - test_loss=2.5315826537911397\n",
            "(878049, 4)\n",
            "Train loss mean: 2.520777359714491 - Test loss mean: 2.532316104191896\n"
          ]
        }
      ],
      "source": [
        "print(\"-\"*80)\n",
        "print(\"Neural Network\")\n",
        "\n",
        "dfs = []\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for j in range(5):\n",
        "    temp_df, train_, test_ = run_neural_network(j)\n",
        "    dfs.append(temp_df)\n",
        "    train_loss.append(train_)\n",
        "    test_loss.append(test_)\n",
        "\n",
        "fin_valid_df = pd.concat(dfs)\n",
        "print(fin_valid_df.shape)\n",
        "print(f\"Train loss mean: {mean(train_loss)} - Test loss mean: {mean(test_loss)}\")\n",
        "fin_valid_df.to_csv(\"drive/MyDrive/model_preds/nn_pred.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA8R-Si_VNdY",
        "outputId": "86d0f055-76cd-4779-fade-12460a83688d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVmXIpUyVKZz"
      },
      "outputs": [],
      "source": [
        "from skopt import gp_minimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBPGXBsp-wox"
      },
      "source": [
        "### Fine tuning - Random Forest (Stacking model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI-A0EfDQsT2"
      },
      "outputs": [],
      "source": [
        "def model_training_rf(params):\n",
        "\n",
        "    files = glob.glob(\"drive/MyDrive/model_preds/*.csv\")\n",
        "    df = None\n",
        "    for f in files:\n",
        "        if df is None:\n",
        "            df = pd.read_csv(f)\n",
        "        else:\n",
        "            temp_df = pd.read_csv(f)\n",
        "            temp_df.drop(['Category', 'kfold'], axis=1, inplace=True)\n",
        "            df = df.merge(temp_df, on=\"id\", how=\"left\")\n",
        "\n",
        "    for fold in range(5):\n",
        "        \n",
        "      train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "      valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "      xtrain = train_df[['ext_pred','rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "      xvalid = valid_df[['ext_pred', 'rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "      ytrain = train_df['Category']\n",
        "      yvalid = valid_df['Category']\n",
        "\n",
        "      scaler = StandardScaler()\n",
        "      xvalid = scaler.fit_transform(xvalid)\n",
        "      n_estimators = params[0]\n",
        "      max_depth = params[1]\n",
        "      max_features = params[2]\n",
        "      \n",
        "      print(params, '\\n')\n",
        "      \n",
        "      mdl = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, random_state=0)\n",
        "      mdl.fit(xtrain, ytrain)\n",
        "      \n",
        "      p = mdl.predict_proba(xvalid)\n",
        "      \n",
        "      return log_loss(yvalid, p)\n",
        "\n",
        "space = [(100, 200), # number of estimators\n",
        "         (5,6), # max depth\n",
        "         ('auto', 'sqrt')] # max features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLxsEaDwXW-q",
        "outputId": "c9ef3ebe-ac24-4cc2-d78d-1c3167e56cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "[200, 6, 'auto'] \n",
            "\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 103.3020\n",
            "Function value obtained: 2.7294\n",
            "Current minimum: 2.7294\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "[200, 5, 'auto'] \n",
            "\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 72.3022\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7057\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "[139, 6, 'sqrt'] \n",
            "\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 56.4989\n",
            "Function value obtained: 2.7327\n",
            "Current minimum: 2.7057\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "[185, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 70.3191\n",
            "Function value obtained: 2.7033\n",
            "Current minimum: 2.7033\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "[144, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 56.7119\n",
            "Function value obtained: 2.7064\n",
            "Current minimum: 2.7033\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "[191, 5, 'auto'] \n",
            "\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 75.8424\n",
            "Function value obtained: 2.7050\n",
            "Current minimum: 2.7033\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "[194, 6, 'sqrt'] \n",
            "\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 85.4850\n",
            "Function value obtained: 2.7281\n",
            "Current minimum: 2.7033\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "[180, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 66.7563\n",
            "Function value obtained: 2.7031\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "[187, 6, 'sqrt'] \n",
            "\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 73.2632\n",
            "Function value obtained: 2.7271\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "[127, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 53.3460\n",
            "Function value obtained: 2.7042\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "[100, 5, 'auto'] \n",
            "\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 41.9202\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "[100, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 42.2176\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n",
            "[200, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 80.7265\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "[100, 5, 'auto'] \n",
            "\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 41.7033\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n",
            "[200, 5, 'auto'] \n",
            "\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 75.8391\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 16 started. Searching for the next optimal point.\n",
            "[100, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 16 ended. Search finished for the next optimal point.\n",
            "Time taken: 41.9890\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 17 started. Searching for the next optimal point.\n",
            "[200, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 17 ended. Search finished for the next optimal point.\n",
            "Time taken: 79.6228\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 18 started. Searching for the next optimal point.\n",
            "[100, 6, 'auto'] \n",
            "\n",
            "Iteration No: 18 ended. Search finished for the next optimal point.\n",
            "Time taken: 46.4276\n",
            "Function value obtained: 2.7355\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 19 started. Searching for the next optimal point.\n",
            "[149, 5, 'auto'] \n",
            "\n",
            "Iteration No: 19 ended. Search finished for the next optimal point.\n",
            "Time taken: 55.6215\n",
            "Function value obtained: 2.7065\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 20 started. Searching for the next optimal point.\n",
            "[100, 5, 'auto'] \n",
            "\n",
            "Iteration No: 20 ended. Search finished for the next optimal point.\n",
            "Time taken: 41.5818\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 21 started. Searching for the next optimal point.\n",
            "[200, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 21 ended. Search finished for the next optimal point.\n",
            "Time taken: 76.4457\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 22 started. Searching for the next optimal point.\n",
            "[100, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 22 ended. Search finished for the next optimal point.\n",
            "Time taken: 37.3226\n",
            "Function value obtained: 2.7062\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 23 started. Searching for the next optimal point.\n",
            "[200, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 23 ended. Search finished for the next optimal point.\n",
            "Time taken: 70.3582\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 24 started. Searching for the next optimal point.\n",
            "[152, 5, 'auto'] \n",
            "\n",
            "Iteration No: 24 ended. Search finished for the next optimal point.\n",
            "Time taken: 55.9052\n",
            "Function value obtained: 2.7060\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 25 started. Searching for the next optimal point.\n",
            "[200, 5, 'auto'] \n",
            "\n",
            "Iteration No: 25 ended. Search finished for the next optimal point.\n",
            "Time taken: 72.3387\n",
            "Function value obtained: 2.7057\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 26 started. Searching for the next optimal point.\n",
            "[168, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 26 ended. Search finished for the next optimal point.\n",
            "Time taken: 61.0070\n",
            "Function value obtained: 2.7036\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 27 started. Searching for the next optimal point.\n",
            "[114, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 27 ended. Search finished for the next optimal point.\n",
            "Time taken: 42.9709\n",
            "Function value obtained: 2.7055\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 28 started. Searching for the next optimal point.\n",
            "[182, 5, 'auto'] \n",
            "\n",
            "Iteration No: 28 ended. Search finished for the next optimal point.\n",
            "Time taken: 65.7603\n",
            "Function value obtained: 2.7031\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 29 started. Searching for the next optimal point.\n",
            "[161, 6, 'sqrt'] \n",
            "\n",
            "Iteration No: 29 ended. Search finished for the next optimal point.\n",
            "Time taken: 65.0907\n",
            "Function value obtained: 2.7270\n",
            "Current minimum: 2.7031\n",
            "Iteration No: 30 started. Searching for the next optimal point.\n",
            "[165, 5, 'sqrt'] \n",
            "\n",
            "Iteration No: 30 ended. Search finished for the next optimal point.\n",
            "Time taken: 67.0927\n",
            "Function value obtained: 2.7045\n",
            "Current minimum: 2.7031\n"
          ]
        }
      ],
      "source": [
        "resultados_gp = gp_minimize(model_training_rf, space, random_state=1, verbose=1, n_calls=30, n_random_starts=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWdnhdcI_Td_"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO-xQ7K9DM2h"
      },
      "source": [
        "### Fine tuning - LightGBM (Stacking model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrtpqheB_V92"
      },
      "outputs": [],
      "source": [
        "def model_training_light(params):\n",
        "\n",
        "    files = glob.glob(\"drive/MyDrive/model_preds/*.csv\")\n",
        "    df = None\n",
        "    for f in files:\n",
        "        if df is None:\n",
        "            df = pd.read_csv(f)\n",
        "        else:\n",
        "            temp_df = pd.read_csv(f)\n",
        "            temp_df.drop(['Category', 'kfold'], axis=1, inplace=True)\n",
        "            df = df.merge(temp_df, on=\"id\", how=\"left\")\n",
        "\n",
        "    for fold in range(5):\n",
        "        \n",
        "      train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "      valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "      xtrain = train_df[['ext_pred','rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "      xvalid = valid_df[['ext_pred', 'rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "      ytrain = train_df['Category']\n",
        "      yvalid = valid_df['Category']\n",
        "\n",
        "      scaler = StandardScaler()\n",
        "      xvalid = scaler.fit_transform(xvalid)\n",
        "      learning_rate = params[0]\n",
        "      num_leaves = params[1]\n",
        "      min_child_samples = params[2]\n",
        "      subsample = params[3]\n",
        "      colsample_bytree = params[4]\n",
        "      \n",
        "      print(params, '\\n')\n",
        "      \n",
        "      mdl = LGBMClassifier(learning_rate=learning_rate, num_leaves=num_leaves, min_child_samples=min_child_samples,\n",
        "                          subsample=subsample, colsample_bytree=colsample_bytree, random_state=0, subsample_freq=1, \n",
        "                          n_estimators=100)\n",
        "      mdl.fit(xtrain, ytrain)\n",
        "      \n",
        "      p = mdl.predict_proba(xvalid)\n",
        "      \n",
        "      return log_loss(yvalid, p)\n",
        "\n",
        "space = [(1e-3, 1e-1, 'log-uniform'), #learning rate\n",
        "         (2, 128), # num_leaves\n",
        "         (1, 100), # min_child_samples\n",
        "         (0.05, 1.0), # subsample\n",
        "         (0.1, 1.0)] # colsample bytree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUbhTwQ-_V7J",
        "outputId": "8f9bfaab-ea2c-4b5b-c20b-37f0399ed606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "[0.09871192514273254, 120, 14, 0.9990884895579377, 0.3124800792567785] \n",
            "\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 169.0380\n",
            "Function value obtained: 2.7106\n",
            "Current minimum: 2.7106\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "[0.006210998932353835, 51, 67, 0.9387621172657304, 0.8616798250174156] \n",
            "\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 279.5853\n",
            "Function value obtained: 2.6819\n",
            "Current minimum: 2.6819\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "[0.004232013397179603, 68, 45, 0.2680983530433343, 0.5809725180523154] \n",
            "\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 322.7758\n",
            "Function value obtained: 2.6805\n",
            "Current minimum: 2.6805\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "[0.0672858974212934, 60, 44, 0.9421713999524447, 0.8005503127028804] \n",
            "\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 272.8354\n",
            "Function value obtained: 2.7353\n",
            "Current minimum: 2.6805\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "[0.027035912483147396, 103, 10, 0.5422449214947946, 0.8785182267810853] \n",
            "\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 323.9752\n",
            "Function value obtained: 2.7398\n",
            "Current minimum: 2.6805\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "[0.045529597892867466, 107, 28, 0.1062810412364853, 0.7034752360620511] \n",
            "\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 333.4595\n",
            "Function value obtained: 2.7398\n",
            "Current minimum: 2.6805\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "[0.01535080081765723, 87, 42, 0.23767335308554222, 0.3606666764912312] \n",
            "\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 272.2829\n",
            "Function value obtained: 2.6817\n",
            "Current minimum: 2.6805\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "[0.0019241559628256106, 101, 42, 0.0824627456265471, 0.661626987829618] \n",
            "\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 302.3385\n",
            "Function value obtained: 2.6804\n",
            "Current minimum: 2.6804\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "[0.02095421812724112, 40, 45, 0.2610183201586061, 0.16602775456833962] \n",
            "\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 180.9816\n",
            "Function value obtained: 2.6808\n",
            "Current minimum: 2.6804\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "[0.008679147174590262, 14, 90, 0.163515944581681, 0.5723194391834011] \n",
            "\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 193.7118\n",
            "Function value obtained: 2.6809\n",
            "Current minimum: 2.6804\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "[0.00834720995744707, 65, 33, 0.5280604826766131, 0.1] \n",
            "\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 174.1706\n",
            "Function value obtained: 2.6804\n",
            "Current minimum: 2.6804\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "[0.002341588925402733, 2, 100, 1.0, 1.0] \n",
            "\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 120.2450\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n",
            "[0.001, 128, 1, 0.05, 1.0] \n",
            "\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 314.5505\n",
            "Function value obtained: 2.6834\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "[0.001, 2, 100, 1.0, 0.1] \n",
            "\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 99.0334\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n",
            "[0.014073669810183927, 2, 100, 1.0, 0.1] \n",
            "\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 98.8668\n",
            "Function value obtained: 2.6804\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 16 started. Searching for the next optimal point.\n",
            "[0.0024462958526991624, 128, 99, 0.05, 0.1] \n",
            "\n",
            "Iteration No: 16 ended. Search finished for the next optimal point.\n",
            "Time taken: 150.1056\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 17 started. Searching for the next optimal point.\n",
            "[0.05833990201978242, 26, 73, 0.2938858549016349, 0.8513278633995661] \n",
            "\n",
            "Iteration No: 17 ended. Search finished for the next optimal point.\n",
            "Time taken: 240.3116\n",
            "Function value obtained: 2.6976\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 18 started. Searching for the next optimal point.\n",
            "[0.001055328527573625, 22, 93, 0.5509742991020065, 0.11145801685604763] \n",
            "\n",
            "Iteration No: 18 ended. Search finished for the next optimal point.\n",
            "Time taken: 170.5419\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 19 started. Searching for the next optimal point.\n",
            "[0.0017565526632699442, 15, 52, 0.9128671672908109, 0.33502782005591203] \n",
            "\n",
            "Iteration No: 19 ended. Search finished for the next optimal point.\n",
            "Time taken: 191.3542\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 20 started. Searching for the next optimal point.\n",
            "[0.001, 4, 62, 0.6221919116130104, 1.0] \n",
            "\n",
            "Iteration No: 20 ended. Search finished for the next optimal point.\n",
            "Time taken: 152.3577\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 21 started. Searching for the next optimal point.\n",
            "[0.001, 82, 1, 0.13748805105672254, 0.2665152029174677] \n",
            "\n",
            "Iteration No: 21 ended. Search finished for the next optimal point.\n",
            "Time taken: 175.7551\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 22 started. Searching for the next optimal point.\n",
            "[0.1, 127, 100, 0.20433448796024822, 0.31865772756869115] \n",
            "\n",
            "Iteration No: 22 ended. Search finished for the next optimal point.\n",
            "Time taken: 173.6066\n",
            "Function value obtained: 2.6857\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 23 started. Searching for the next optimal point.\n",
            "[0.018642739698509672, 102, 100, 0.9154434046198878, 1.0] \n",
            "\n",
            "Iteration No: 23 ended. Search finished for the next optimal point.\n",
            "Time taken: 342.7078\n",
            "Function value obtained: 2.6902\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 24 started. Searching for the next optimal point.\n",
            "[0.001, 121, 100, 0.636900163231921, 0.617838919610038] \n",
            "\n",
            "Iteration No: 24 ended. Search finished for the next optimal point.\n",
            "Time taken: 325.4346\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 25 started. Searching for the next optimal point.\n",
            "[0.009332442713114156, 126, 68, 0.6962347965309404, 0.2777664579539887] \n",
            "\n",
            "Iteration No: 25 ended. Search finished for the next optimal point.\n",
            "Time taken: 173.5730\n",
            "Function value obtained: 2.6804\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 26 started. Searching for the next optimal point.\n",
            "[0.001, 41, 72, 0.791445914714094, 0.703614238710175] \n",
            "\n",
            "Iteration No: 26 ended. Search finished for the next optimal point.\n",
            "Time taken: 258.1098\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 27 started. Searching for the next optimal point.\n",
            "[0.001, 23, 1, 0.12375399539029212, 0.6044429720365557] \n",
            "\n",
            "Iteration No: 27 ended. Search finished for the next optimal point.\n",
            "Time taken: 214.7942\n",
            "Function value obtained: 2.6807\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 28 started. Searching for the next optimal point.\n",
            "[0.001, 120, 29, 0.8094438852372347, 0.1] \n",
            "\n",
            "Iteration No: 28 ended. Search finished for the next optimal point.\n",
            "Time taken: 175.4232\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 29 started. Searching for the next optimal point.\n",
            "[0.0030125853708195885, 2, 1, 0.8085454067852353, 0.1] \n",
            "\n",
            "Iteration No: 29 ended. Search finished for the next optimal point.\n",
            "Time taken: 108.4980\n",
            "Function value obtained: 2.6803\n",
            "Current minimum: 2.6803\n",
            "Iteration No: 30 started. Searching for the next optimal point.\n",
            "[0.019083963477534424, 2, 66, 0.21670463639942616, 0.1] \n",
            "\n",
            "Iteration No: 30 ended. Search finished for the next optimal point.\n",
            "Time taken: 107.0199\n",
            "Function value obtained: 2.6806\n",
            "Current minimum: 2.6803\n"
          ]
        }
      ],
      "source": [
        "resultados_light = gp_minimize(model_training_light, space, random_state=1, verbose=1, n_calls=30, n_random_starts=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdCfkAcYISD"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Light_results = [0.001, 2, 100, 1.0, 0.1]"
      ],
      "metadata": {
        "id": "5_qPmd72_31J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPMqGsEx-aXy"
      },
      "source": [
        "### Stacking model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LightGBM - Level 2"
      ],
      "metadata": {
        "id": "lhR457KUD40C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsNKRqhweIkz"
      },
      "outputs": [],
      "source": [
        "def meta_model_training_light(pred_df: pd.DataFrame, fold: int, params: list):\n",
        "\n",
        "    train_df = pred_df[pred_df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = pred_df[pred_df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    xtrain = train_df[['ext_pred','rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "    xvalid = valid_df[['ext_pred', 'rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "    ytrain = train_df['Category']\n",
        "    yvalid = valid_df['Category']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    xvalid = scaler.fit_transform(xvalid)\n",
        "    xtrain = scaler.fit_transform(xtrain)\n",
        "    column_name = 'light_pred_level2'\n",
        "\n",
        "    clf = LGBMClassifier(learning_rate=params[0], num_leaves=params[1], min_child_samples=params[2],\n",
        "                    subsample=params[3], colsample_bytree=params[4], random_state=0, subsample_freq=1, \n",
        "                    n_estimators=100)\n",
        "    \n",
        "    clf.fit(xtrain, ytrain)  \n",
        "\n",
        "    pred_train = clf.predict_proba(xtrain)\n",
        "    pred_test = clf.predict_proba(xvalid)\n",
        "\n",
        "    train_loss = log_loss(ytrain, pred_train)\n",
        "    test_loss = log_loss(yvalid, pred_test)\n",
        "    print(f\"fold={fold}, train_loss={train_loss} - test_loss={test_loss}\")\n",
        "\n",
        "\n",
        "    prob_list = []\n",
        "    for i in pred_test:\n",
        "        max_prob = i.max()\n",
        "        probs = list(i)\n",
        "        prob = probs.index(max_prob)\n",
        "        prob_list.append(prob)\n",
        "\n",
        "    valid_df[column_name] = prob_list\n",
        "\n",
        "    return valid_df[['id', 'Category','kfold', column_name]], train_loss, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyMv94pkeInT"
      },
      "outputs": [],
      "source": [
        "files = glob.glob(\"drive/MyDrive/model_preds/*.csv\")\n",
        "df = None\n",
        "for f in files:\n",
        "    if df is None:\n",
        "        df = pd.read_csv(f)\n",
        "    else:\n",
        "        temp_df = pd.read_csv(f)\n",
        "        temp_df.drop(['Category', 'kfold'], axis=1, inplace=True)\n",
        "        df = df.merge(temp_df, on=\"id\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_light"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvX0HvKhCGt2",
        "outputId": "9d327f18-74e4-4de8-ea1e-db0235683018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.001, 2, 100, 1.0, 0.1]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evdUowWyeIsP",
        "outputId": "06386f45-506f-4c4d-c051-c15b973e9290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Meta model\n",
            "fold=0, train_loss=2.6803260358443297 - test_loss=2.6802891946778957\n",
            "fold=1, train_loss=2.680317423840633 - test_loss=2.680324592549758\n",
            "fold=2, train_loss=2.680315157425217 - test_loss=2.680334596279305\n",
            "fold=3, train_loss=2.680307976471803 - test_loss=2.6803627334338076\n",
            "fold=4, train_loss=2.680319773951876 - test_loss=2.680312669061236\n",
            "(878049, 4)\n",
            "Train loss: 2.6803172735067715 - Test loss: 2.6803247572004003\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"-\"*80)\n",
        "print(\"Meta model\")\n",
        "\n",
        "dfs = []\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for j in range(5):\n",
        "    temp_df, train_, test_ = meta_model_training_light(df, j, resultados_light)\n",
        "    dfs.append(temp_df)\n",
        "    train_loss.append(train_)\n",
        "    test_loss.append(test_)\n",
        "\n",
        "fin_valid_df = pd.concat(dfs)\n",
        "print(fin_valid_df.shape)\n",
        "print(f\"Train loss: {mean(train_loss)} - Test loss: {mean(test_loss)}\")\n",
        "fin_valid_df.to_csv(\"drive/MyDrive/model_preds/LightGBM_Level2.csv\", index=False)\n",
        "print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GP_results = [180, 5, 'sqrt']"
      ],
      "metadata": {
        "id": "D4FOtcRJ___L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Level 2"
      ],
      "metadata": {
        "id": "yIKvs_lA_Ep7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def meta_model_training_rf2(pred_df: pd.DataFrame, fold: int, params: list):\n",
        "\n",
        "    train_df = pred_df[pred_df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = pred_df[pred_df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    xtrain = train_df[['ext_pred','rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "    xvalid = valid_df[['ext_pred', 'rf_pred', 'gnb_pred', 'xgb_pred', 'lr_pred', 'nn_pred']].values\n",
        "    ytrain = train_df['Category']\n",
        "    yvalid = valid_df['Category']\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    xvalid = scaler.fit_transform(xvalid)\n",
        "    xtrain = scaler.fit_transform(xtrain)\n",
        "    column_name = 'rf_pred_level2'\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=params[0], max_depth=params[1], max_features=params[2], random_state=0)\n",
        "\n",
        "    clf.fit(xtrain, ytrain)  \n",
        "\n",
        "    pred_train = clf.predict_proba(xtrain)\n",
        "    pred_test = clf.predict_proba(xvalid)\n",
        "\n",
        "    train_loss = log_loss(ytrain, pred_train)\n",
        "    test_loss = log_loss(yvalid, pred_test)\n",
        "    print(f\"fold={fold}, train_loss={train_loss} - test_loss={test_loss}\")\n",
        "\n",
        "\n",
        "    prob_list = []\n",
        "    for i in pred_test:\n",
        "        max_prob = i.max()\n",
        "        probs = list(i)\n",
        "        prob = probs.index(max_prob)\n",
        "        prob_list.append(prob)\n",
        "\n",
        "    valid_df[column_name] = prob_list\n",
        "\n",
        "    return valid_df[['id', 'Category','kfold', column_name]], train_loss, test_loss"
      ],
      "metadata": {
        "id": "PJ2o4xX7-YEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(\"drive/MyDrive/model_preds/*.csv\")\n",
        "df = None\n",
        "for f in files:\n",
        "    if df is None:\n",
        "        df = pd.read_csv(f)\n",
        "    else:\n",
        "        temp_df = pd.read_csv(f)\n",
        "        temp_df.drop(['Category', 'kfold'], axis=1, inplace=True)\n",
        "        df = df.merge(temp_df, on=\"id\", how=\"left\")"
      ],
      "metadata": {
        "id": "iVMshdz4-YBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-\"*80)\n",
        "print(\"Meta model\")\n",
        "\n",
        "dfs = []\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for j in range(5):\n",
        "    temp_df, train_, test_ = meta_model_training_rf2(df, j, resultados_gp.x)\n",
        "    dfs.append(temp_df)\n",
        "    train_loss.append(train_)\n",
        "    test_loss.append(test_)\n",
        "\n",
        "fin_valid_df = pd.concat(dfs)\n",
        "print(fin_valid_df.shape)\n",
        "print(f\"Train loss: {mean(train_loss)} - Test loss: {mean(test_loss)}\")\n",
        "fin_valid_df.to_csv(\"drive/MyDrive/model_preds/rf_Level2.csv\", index=False)\n",
        "print(\"-\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vei5MzA3-X-U",
        "outputId": "92baf407-e9c4-4f5b-cb04-d2ce446a36a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Meta model\n",
            "fold=0, train_loss=2.679056107834159 - test_loss=2.681194517020028\n",
            "fold=1, train_loss=2.679036707965257 - test_loss=2.682020009750325\n",
            "fold=2, train_loss=2.6790299072017496 - test_loss=2.6807806600093813\n",
            "fold=3, train_loss=2.6790347490391033 - test_loss=2.682145021547842\n",
            "fold=4, train_loss=2.6790362698665104 - test_loss=2.681319678807353\n",
            "(878049, 4)\n",
            "Train loss: 2.679038748381356 - Test loss: 2.681491977426986\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The best results were found using neural networks. It was evaluated based on the log loss metric."
      ],
      "metadata": {
        "id": "l78EFg2UA8m2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKBwTq2n-X4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGZu7HFX-X1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdjFbnJ9-Xyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARSzE-pFeIul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}